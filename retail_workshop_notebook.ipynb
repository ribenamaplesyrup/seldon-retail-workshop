{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "retail_workshop_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ei4WoQXTZtjq",
        "uRnKV9QLcepI",
        "kZXr3-bfcrZr",
        "0zZjwLAlAoXg",
        "DlrAixGMA_Hs",
        "rjspFW0AFlHS",
        "ZG6kWCMDOHsR",
        "hmI8brYLieU-",
        "mBPpQneC-cqr",
        "ncuCKhNiDto3",
        "VMMHiGZXGnQ3",
        "pNDr5nwpG20x",
        "ilQ9JJGUIpVW"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNI8xSiiBd24"
      },
      "source": [
        "!pip install seldon-deploy-sdk\n",
        "!pip install alibi\n",
        "!pip install alibi-detect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9RurRkiZljs"
      },
      "source": [
        "from sklearn import preprocessing, model_selection, metrics, feature_selection\n",
        "from sklearn.model_selection import GridSearchCV, learning_curve\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import neighbors, linear_model, svm, tree, ensemble\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import numpy as np\n",
        "import pickle \n",
        "import joblib\n",
        "import dill\n",
        "import os \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Dense, InputLayer\n",
        "from alibi.explainers import AnchorTabular\n",
        "from alibi_detect.datasets import fetch_kdd\n",
        "from alibi_detect.models.tensorflow.losses import elbo\n",
        "from alibi_detect.od import OutlierVAE\n",
        "from alibi_detect.cd import TabularDrift\n",
        "from alibi_detect.utils.data import create_outlier_batch\n",
        "from alibi_detect.utils.fetching import fetch_detector\n",
        "from alibi_detect.utils.saving import save_detector, load_detector\n",
        "from alibi_detect.utils.visualize import plot_instance_score, plot_feature_outlier_tabular, plot_roc\n",
        "from seldon_deploy_sdk import Configuration, ApiClient, SeldonDeploymentsApi, OutlierDetectorApi, DriftDetectorApi\n",
        "from seldon_deploy_sdk.auth import OIDCAuthenticator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei4WoQXTZtjq"
      },
      "source": [
        "##Model Training\n",
        "\n",
        "In this section we will adjust a classifier that will classify consumers in the different client categories. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8ZLBwUhaTFx"
      },
      "source": [
        "class Class_Fit(object):\n",
        "    def __init__(self, clf, params=None):\n",
        "        if params:            \n",
        "            self.clf = clf(**params)\n",
        "        else:\n",
        "            self.clf = clf()\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict(x)\n",
        "    \n",
        "    def grid_search(self, parameters, Kfold):\n",
        "        self.grid = GridSearchCV(estimator = self.clf, param_grid = parameters, cv = Kfold)\n",
        "        \n",
        "    def grid_fit(self, X, Y):\n",
        "        self.grid.fit(X, Y)\n",
        "        \n",
        "    def grid_predict(self, X, Y):\n",
        "        self.predictions = self.grid.predict(X)\n",
        "        print(\"Precision: {:.2f} % \".format(100*metrics.accuracy_score(Y, self.predictions)))\n",
        "       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SXGONbMbSFW"
      },
      "source": [
        "Mean refers to the average amount spent within each transaction. Each category represents a different category of products and was derived through k-means clustering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8iVe96QbMyQ"
      },
      "source": [
        "columns = ['mean', 'categ_0', 'categ_1', 'categ_2', 'categ_3', 'categ_4' ] # change to feature_names?\n",
        "class_names = ['0','1','2','3','4','5','6','7','8','9','10']\n",
        "X_train = np.load('data/X_train.npy')\n",
        "Y_train = np.load('data/Y_train.npy')\n",
        "X_test = np.load('data/X_test.npy')\n",
        "Y_test = np.load('data/Y_test.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRnKV9QLcepI"
      },
      "source": [
        "## Support Vector Machine "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZi7oQJjb7wN"
      },
      "source": [
        "svc = Class_Fit(clf = svm.LinearSVC)\n",
        "svc.grid_search(parameters = [{'C':np.logspace(-2,2,10)}], Kfold = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGfta5UEb9Y8"
      },
      "source": [
        "svc.grid_fit(X = X_train, Y = Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ6QXLKMcJ7d"
      },
      "source": [
        "svc.grid_predict(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZXr3-bfcrZr"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se7kBpFlcUm1"
      },
      "source": [
        "lr = Class_Fit(clf = linear_model.LogisticRegression)\n",
        "lr.grid_search(parameters = [{'C':np.logspace(-2,2,20)}], Kfold = 5)\n",
        "lr.grid_fit(X = X_train, Y = Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zllnrVFtc1PN"
      },
      "source": [
        "lr.grid_predict(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uxLmN1IElOB"
      },
      "source": [
        "lr.grid.best_estimator_.predict_proba([[169.44666667,  19.82924814,  22.28823229,  28.95207932, 23.49411811,   5.43632215]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYjuhrLrCDpL"
      },
      "source": [
        "models = ['lr','svc']\n",
        "\n",
        "for model in models:\n",
        "  if not os.path.exists('models/' + model):\n",
        "    os.mkdir('models/' + model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68IRCKnhddNx"
      },
      "source": [
        "filename = 'models/lr/model.joblib'\n",
        "joblib.dump(lr.grid.best_estimator_, filename)\n",
        "\n",
        "filename = 'models/svc/model.joblib'\n",
        "joblib.dump(svc.grid.best_estimator_, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zZjwLAlAoXg"
      },
      "source": [
        "## Push model artefacts to GCP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlU3AfYG_BtN"
      },
      "source": [
        "# Push artefact to GCP\n",
        "# !gsutil cp model/<.sav model file> gs://tom-seldon-examples/datareply-workshop/<YOUR NAME>/<MODEL TYPE>/model.sav\n",
        "!gsutil cp models/lr/model.joblib gs://tom-seldon-examples/datareply-workshop/sean/lr/model.joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_04eLsqAN1o"
      },
      "source": [
        "!gsutil cp models/svc/model.joblib gs://tom-seldon-examples/datareply-workshop/sean/svc/model.joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlrAixGMA_Hs"
      },
      "source": [
        "## Deploy models to Seldon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS8XO97eBMGF"
      },
      "source": [
        "We can now deploy our model to the dedicated Seldon Deploy cluster which we have configured for this workshop. To do so we will interact with the Seldon Deploy SDK and deploy our model using that.\n",
        "\n",
        "First, setting up the configuration and authentication required to access the cluster. Make sure to fill in the SD_IP variable to be the same as the cluster you are using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOCjkhaIBtVF"
      },
      "source": [
        "SD_IP = \"139.59.203.129\"\n",
        "\n",
        "config = Configuration()\n",
        "config.host = f\"http://{SD_IP}/seldon-deploy/api/v1alpha1\"\n",
        "config.oidc_client_id = \"sd-api\"\n",
        "config.oidc_server = f\"http://{SD_IP}/auth/realms/deploy-realm\"\n",
        "\n",
        "def auth():\n",
        "    auth = OIDCAuthenticator(config)\n",
        "    config.access_token = auth.authenticate(\"admin@seldon.io\", \"12341234\")\n",
        "    api_client = ApiClient(config)\n",
        "    return api_client"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7gHzz9JBwLZ"
      },
      "source": [
        "DEPLOYMENT_NAME = \"customer-lr\"\n",
        "NAMESPACE = \"test\"\n",
        "MODEL_LOCATION = \"gs://tom-seldon-examples/datareply-workshop/sean/lr\"\n",
        "\n",
        "PREPACKAGED_SERVER = \"SKLEARN_SERVER\"\n",
        "\n",
        "CPU_REQUESTS = \"1\"\n",
        "MEMORY_REQUESTS = \"1Gi\"\n",
        "\n",
        "CPU_LIMITS = \"1\"\n",
        "MEMORY_LIMITS = \"1Gi\"\n",
        "\n",
        "mldeployment = {\n",
        "    \"kind\": \"SeldonDeployment\",\n",
        "    \"metadata\": {\n",
        "        \"name\": DEPLOYMENT_NAME,\n",
        "        \"namespace\": NAMESPACE,\n",
        "        \"labels\": {\n",
        "            \"fluentd\": \"true\"\n",
        "        }\n",
        "    },\n",
        "    \"apiVersion\": \"machinelearning.seldon.io/v1alpha2\",\n",
        "    \"spec\": {\n",
        "        \"name\": DEPLOYMENT_NAME,\n",
        "        \"annotations\": {\n",
        "            \"seldon.io/engine-seldon-log-messages-externally\": \"true\"\n",
        "        },\n",
        "        \"protocol\": \"seldon\",\n",
        "        \"transport\": \"rest\",\n",
        "        \"predictors\": [\n",
        "            {\n",
        "                \"componentSpecs\": [\n",
        "                    {\n",
        "                        \"spec\": {\n",
        "                            \"containers\": [\n",
        "                                {\n",
        "                                    \"name\": f\"{DEPLOYMENT_NAME}-container\",\n",
        "                                    \"resources\": {\n",
        "                                        \"requests\": {\n",
        "                                            \"cpu\": CPU_REQUESTS,\n",
        "                                            \"memory\": MEMORY_REQUESTS\n",
        "                                        },\n",
        "                                        \"limits\": {\n",
        "                                            \"cpu\": CPU_LIMITS,\n",
        "                                            \"memory\": MEMORY_LIMITS\n",
        "                                        }\n",
        "                                    }\n",
        "                                }\n",
        "                            ]\n",
        "                        }\n",
        "                    }\n",
        "                ],\n",
        "                \"name\": \"default\",\n",
        "                \"replicas\": 1,\n",
        "                \"traffic\": 100,\n",
        "                \"graph\": {\n",
        "                    \"implementation\": PREPACKAGED_SERVER,\n",
        "                    \"modelUri\": MODEL_LOCATION,\n",
        "                    \"name\": f\"{DEPLOYMENT_NAME}-container\",\n",
        "                    \"endpoint\": {\n",
        "                        \"type\": \"REST\"\n",
        "                    },\n",
        "                    \"parameters\": [],\n",
        "                    \"children\": [],\n",
        "                    \"logger\": {\n",
        "                        \"mode\": \"all\"\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"status\": {}\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeKpuObJCHA3"
      },
      "source": [
        "deployment_api = SeldonDeploymentsApi(auth())\n",
        "deployment_api.create_seldon_deployment(namespace=NAMESPACE, mldeployment=mldeployment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjspFW0AFlHS"
      },
      "source": [
        "## Explainer\n",
        "\n",
        "Next, we shall train an explainer to glean deeper insights into the decisions being made by our model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMowappmHKz1"
      },
      "source": [
        "clf = lr.grid.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8CQR0mjC6gQ"
      },
      "source": [
        "predict_fn = lambda x: clf.predict(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNLvR53vG7Yb"
      },
      "source": [
        "explainer = AnchorTabular(predict_fn, columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQc3nvlIHofS"
      },
      "source": [
        "explainer.fit(X_train, disc_perc=(25, 50, 75))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AgHZXu3Hr52"
      },
      "source": [
        "idx = 0\n",
        "print('Prediction: ', class_names[explainer.predictor(X_test[idx].reshape(1, -1))[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FD98jlOI15c"
      },
      "source": [
        "explanation = explainer.explain(X_test[idx], threshold=0.9)\n",
        "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
        "print('Precision: %.2f' % explanation.precision)\n",
        "print('Coverage: %.2f' % explanation.coverage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6LUjpMSI-BP"
      },
      "source": [
        "with open(\"models/lr/explainer.dill\", \"wb\") as model_f:\n",
        "        dill.dump(explainer, model_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO1MuyEJP3LM"
      },
      "source": [
        "!python -V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_kFLlzaLAkd"
      },
      "source": [
        "!gsutil cp models/lr/explainer.dill gs://tom-seldon-examples/datareply-workshop/sean/lr/explainer.dill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG6kWCMDOHsR"
      },
      "source": [
        "## Deployment\n",
        "\n",
        "We can now deploy our explainer alongside our model. First we define the explainer configuration. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTq-3i5XMZDh"
      },
      "source": [
        "EXPLAINER_TYPE = \"AnchorTabular\"\n",
        "EXPLAINER_URI = \"gs://tom-seldon-examples/datareply-workshop/sean/lr\"\n",
        "\n",
        "explainer_spec = {\n",
        "                    \"type\": EXPLAINER_TYPE,\n",
        "                    \"modelUri\": EXPLAINER_URI,\n",
        "                    \"containerSpec\": {\n",
        "                        \"name\": \"\",\n",
        "                        \"resources\": {}\n",
        "                    }\n",
        "                }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr7cIsDPOZ0T"
      },
      "source": [
        "mldeployment['spec']['predictors'][0]['explainer'] = explainer_spec\n",
        "mldeployment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEE1Ng-IOeR_"
      },
      "source": [
        "deployment_api = SeldonDeploymentsApi(auth())\n",
        "deployment_api.create_seldon_deployment(namespace=NAMESPACE, mldeployment=mldeployment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmI8brYLieU-"
      },
      "source": [
        "## Outlier Detection \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBPpQneC-cqr"
      },
      "source": [
        "## Method\n",
        "\n",
        "The Variational Auto-Encoder ([VAE](https://arxiv.org/abs/1312.6114)) outlier detector is first trained on a batch of unlabeled, but normal (*inlier*) data. Unsupervised training is desireable since labeled data is often scarce. The VAE detector tries to reconstruct the input it receives. If the input data cannot be reconstructed well, the reconstruction error is high and the data can be flagged as an outlier. The reconstruction error is either measured as the mean squared error (MSE) between the input and the reconstructed instance or as the probability that both the input and the reconstructed instance are generated by the same process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qWd7Y0H-8H-"
      },
      "source": [
        "normal_batch = create_outlier_batch(X_train, Y_train, n_samples=2886, perc_outlier=0)\n",
        "X_train, y_train = normal_batch.data.astype('float'), normal_batch.target\n",
        "print(X_train.shape, y_train.shape)\n",
        "print('{}% outliers'.format(100 * y_train.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bos3TdDbDl1A"
      },
      "source": [
        "mean, stdev = X_train.mean(axis=0), X_train.std(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBtHhDH8DnFo"
      },
      "source": [
        "X_train = (X_train - mean) / stdev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncuCKhNiDto3"
      },
      "source": [
        "## Load or define outlier detector\n",
        "\n",
        "The pretrained outlier and adversarial detectors used in the example notebooks can be found [here](https://console.cloud.google.com/storage/browser/seldon-models/alibi-detect). You can use the built-in ```fetch_detector``` function which saves the pre-trained models in a local directory ```filepath``` and loads the detector. Alternatively, you can train a detector from scratch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwx_xqTwDp7O"
      },
      "source": [
        "load_outlier_detector = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSvBvODuDxtb"
      },
      "source": [
        "filepath = '/content/models/OutlierVAE'\n",
        "if not os.path.exists(filepath):\n",
        "  os.mkdir(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZewHIB-EBkz"
      },
      "source": [
        "# define model, initialize, train and save outlier detector\n",
        "    \n",
        "n_features = X_train.shape[1]\n",
        "latent_dim = 2\n",
        "    \n",
        "encoder_net = tf.keras.Sequential(\n",
        "    [\n",
        "     InputLayer(input_shape=(n_features,)),\n",
        "     Dense(20, activation=tf.nn.relu),\n",
        "     Dense(15, activation=tf.nn.relu),\n",
        "     Dense(7, activation=tf.nn.relu)\n",
        "     ])\n",
        "\n",
        "decoder_net = tf.keras.Sequential(\n",
        "    [\n",
        "     InputLayer(input_shape=(latent_dim,)),\n",
        "     Dense(7, activation=tf.nn.relu),\n",
        "     Dense(15, activation=tf.nn.relu),\n",
        "     Dense(20, activation=tf.nn.relu),\n",
        "     Dense(n_features, activation=None)\n",
        "     ])\n",
        "    \n",
        "# initialize outlier detector\n",
        "od = OutlierVAE(threshold=None,  # threshold for outlier score\n",
        "                score_type='mse',  # use MSE of reconstruction error for outlier detection\n",
        "                encoder_net=encoder_net,  # can also pass VAE model instead\n",
        "                decoder_net=decoder_net,  # of separate encoder and decoder\n",
        "                latent_dim=latent_dim,\n",
        "                samples=5)\n",
        "# train\n",
        "od.fit(X_train,\n",
        "       loss_fn=elbo,\n",
        "       cov_elbo=dict(sim=.01),\n",
        "       epochs=30,\n",
        "       verbose=True)\n",
        "\n",
        "# save the trained outlier detector\n",
        "save_detector(od, filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGL9gc6UGMXo"
      },
      "source": [
        "The warning tells us we still need to set the outlier threshold. This can be done with the `infer_threshold` method. We need to pass a batch of instances and specify what percentage of those we consider to be normal via `threshold_perc`. Let's assume we have some data which we know contains around 5% outliers. The percentage of outliers can be set with `perc_outlier` in the `create_outlier_batch` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8GbfajFGCZV"
      },
      "source": [
        "np.random.seed(0)\n",
        "perc_outlier = 5\n",
        "threshold_batch = create_outlier_batch(X_train, Y_train, n_samples=100, perc_outlier=perc_outlier)\n",
        "X_threshold, y_threshold = threshold_batch.data.astype('float'), threshold_batch.target\n",
        "X_threshold = (X_threshold - mean) / stdev\n",
        "print('{}% outliers'.format(100 * y_threshold.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWKoCcojGaEI"
      },
      "source": [
        "od.infer_threshold(X_threshold, threshold_perc=100-perc_outlier)\n",
        "print('New threshold: {}'.format(od.threshold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw60AftDGcih"
      },
      "source": [
        "save_detector(od, filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMMHiGZXGnQ3"
      },
      "source": [
        "## Detect outliers\n",
        "\n",
        "We now generate a batch of data with 10% outliers and detect the outliers in the batch. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MtuBEz8Ggqp"
      },
      "source": [
        "np.random.seed(1)\n",
        "outlier_batch = create_outlier_batch(X_train, Y_train, n_samples=2886, perc_outlier=10)\n",
        "X_outlier, y_outlier = outlier_batch.data.astype('float'), outlier_batch.target\n",
        "X_outlier = (X_outlier - mean) / stdev\n",
        "print(X_outlier.shape, y_outlier.shape)\n",
        "print('{}% outliers'.format(100 * y_outlier.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQayaNVgGwWn"
      },
      "source": [
        "Predict outliers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdOja4ZDGtw9"
      },
      "source": [
        "od_preds = od.predict(X_outlier,\n",
        "                      outlier_type='instance',    # use 'feature' or 'instance' level\n",
        "                      return_feature_score=True,  # scores used to determine outliers\n",
        "                      return_instance_score=True)\n",
        "print(list(od_preds['data'].keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNDr5nwpG20x"
      },
      "source": [
        "## Display results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOP_-6xvG0Ll"
      },
      "source": [
        "labels = outlier_batch.target_names\n",
        "y_pred = od_preds['data']['is_outlier']\n",
        "f1 = f1_score(y_outlier, y_pred)\n",
        "print('F1 score: {:.4f}'.format(f1))\n",
        "cm = confusion_matrix(y_outlier, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "sns.heatmap(df_cm, annot=True, cbar=True, linewidths=.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv3kkWnZINJl"
      },
      "source": [
        "plot_instance_score(od_preds, y_outlier, labels, od.threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UbNaXO_IShg"
      },
      "source": [
        "roc_data = {'VAE': {'scores': od_preds['data']['instance_score'], 'labels': y_outlier}}\n",
        "plot_roc(roc_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilQ9JJGUIpVW"
      },
      "source": [
        "## Investigate instance level outlier\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "\n",
        "\n",
        "We can now take a closer look at some of the individual predictions on `X_outlier`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3FlG8qBIu1A"
      },
      "source": [
        "X_recon = od.vae(X_outlier).numpy()  # reconstructed instances by the VAE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7RR5fEkIyK8"
      },
      "source": [
        "plot_feature_outlier_tabular(od_preds,\n",
        "                             X_outlier,\n",
        "                             X_recon=X_recon,\n",
        "                             threshold=od.threshold,\n",
        "                             instance_ids=None,  # pass a list with indices of instances to display\n",
        "                             max_instances=5,  # max nb of instances to display\n",
        "                             top_n=5,  # only show top_n features ordered by outlier score\n",
        "                             outliers_only=False,  # only show outlier predictions\n",
        "                             feature_names=columns,  # add feature names\n",
        "                             figsize=(20, 30))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkG5fKciIazt"
      },
      "source": [
        "## Drift Detection\n",
        "\n",
        "### Method\n",
        "\n",
        "The drift detector applies feature-wise two-sample [Kolmogorov-Smirnov](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test) (K-S) tests for the continuous numerical features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3FRyfX1KQEO"
      },
      "source": [
        "We split the data in a reference set and 2 test sets on which we test the data drift:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7SCT9OlIZGP"
      },
      "source": [
        "n_ref = 900\n",
        "n_test = 900\n",
        "\n",
        "X_ref, X_t0, X_t1 = X_train[:n_ref], X_train[n_ref:n_ref + n_test], X_train[n_ref + n_test:n_ref + 2 * n_test]\n",
        "X_ref.shape, X_t0.shape, X_t1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anEOqBuOKWWR"
      },
      "source": [
        "### Detect drift\n",
        "\n",
        "Initialize the detector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wofaIs0KM3u"
      },
      "source": [
        "cd = TabularDrift(X_ref, p_val=.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQVFSz1-K0Da"
      },
      "source": [
        "preds = cd.predict(X_t0)\n",
        "labels = ['No!', 'Yes!']\n",
        "print('Drift? {}'.format(labels[preds['data']['is_drift']]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNeHKA7eK5oL"
      },
      "source": [
        "for f in range(cd.n_features):\n",
        "    stat = 'K-S'\n",
        "    fname = columns[f]\n",
        "    stat_val, p_val = preds['data']['distance'][f], preds['data']['p_val'][f]\n",
        "    print(f'{fname} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVHrtyl2LekN"
      },
      "source": [
        "None of the feature-level p-values are below the threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M84FTiNLVCB"
      },
      "source": [
        "preds['data']['threshold']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX2S4WAFLmjr"
      },
      "source": [
        "If you are interested in individual feature-wise drift, this is also possible:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_G38h4OLr8X"
      },
      "source": [
        "fpreds = cd.predict(X_t0, drift_type='feature')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5rxryKxLtNx"
      },
      "source": [
        "for f in range(cd.n_features):\n",
        "    stat = 'K-S'\n",
        "    fname = columns[f]\n",
        "    is_drift = fpreds['data']['is_drift'][f]\n",
        "    stat_val, p_val = fpreds['data']['distance'][f], fpreds['data']['p_val'][f]\n",
        "    print(f'{fname} -- Drift? {labels[is_drift]} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddrgyHpoL2ZR"
      },
      "source": [
        "preds = cd.predict(X_t1)\n",
        "labels = ['No!', 'Yes!']\n",
        "print('Drift? {}'.format(labels[preds['data']['is_drift']]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el-goYR5L8nD"
      },
      "source": [
        "We can again investigate the individual features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS_vpe8XMB2K"
      },
      "source": [
        "for f in range(cd.n_features):\n",
        "    stat = 'K-S'\n",
        "    fname = columns[f]\n",
        "    is_drift = (preds['data']['p_val'][f] < preds['data']['threshold']).astype(int)\n",
        "    stat_val, p_val = preds['data']['distance'][f], preds['data']['p_val'][f]\n",
        "    print(f'{fname} -- Drift? {labels[is_drift]} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}